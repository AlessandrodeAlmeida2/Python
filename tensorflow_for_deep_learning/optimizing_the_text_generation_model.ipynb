{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Optimizing the Text Generation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxhW3mtLmfb"
      },
      "source": [
        "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "outputId": "b2960193-e12f-4a67-a2b9-2e6b21409b8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-04 17:45:03--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.202.100, 74.125.202.102, 74.125.202.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.202.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jv222m6so6avipg52dj36rn2cfhtdd9d/1685900700000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=5d02d96d-d5b9-423d-95d5-5af8bf9d884e [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-06-04 17:45:06--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/jv222m6so6avipg52dj36rn2cfhtdd9d/1685900700000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=5d02d96d-d5b9-423d-95d5-5af8bf9d884e\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 64.233.183.132, 2607:f8b0:4001:c0b::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|64.233.183.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M   120MB/s    in 0.6s    \n",
            "\n",
            "2023-06-04 17:45:07 (120 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9x-7dWihxx"
      },
      "source": [
        "## 250 Songs\n",
        "\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LRmPPJegovBe"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kIGedF3XjHj4",
        "outputId": "9a4fcfeb-76fd-46ad-86bc-c642bb721bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"
          ]
        }
      ],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kkLAf3HmkPSo"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a (Better) Text Generation Model\n",
        "\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7nHOp6uWlP_P",
        "outputId": "1e21e634-e4d9-4526-d364-7c3ed391ee86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 31s 14ms/step - loss: 5.9828 - accuracy: 0.0461\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.6736 - accuracy: 0.0511\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.4941 - accuracy: 0.0611\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.3323 - accuracy: 0.0856\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.1905 - accuracy: 0.1024\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.0517 - accuracy: 0.1176\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 4.9002 - accuracy: 0.1339\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.7510 - accuracy: 0.1470\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.6259 - accuracy: 0.1606\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.5105 - accuracy: 0.1723\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.4006 - accuracy: 0.1874\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.2975 - accuracy: 0.2000\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.2065 - accuracy: 0.2100\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.1221 - accuracy: 0.2205\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 4.0445 - accuracy: 0.2305\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.9746 - accuracy: 0.2394\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.9085 - accuracy: 0.2492\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.8496 - accuracy: 0.2553\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.7922 - accuracy: 0.2632\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.7391 - accuracy: 0.2700\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.6925 - accuracy: 0.2775\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.6455 - accuracy: 0.2841\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.6031 - accuracy: 0.2898\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.5602 - accuracy: 0.2986\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.5226 - accuracy: 0.3017\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.4852 - accuracy: 0.3085\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.4499 - accuracy: 0.3140\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.4208 - accuracy: 0.3176\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.3849 - accuracy: 0.3245\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.3564 - accuracy: 0.3284\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.3265 - accuracy: 0.3330\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2990 - accuracy: 0.3377\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2646 - accuracy: 0.3431\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2474 - accuracy: 0.3452\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.2228 - accuracy: 0.3484\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1923 - accuracy: 0.3536\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1651 - accuracy: 0.3572\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 3.1460 - accuracy: 0.3623\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 3.1265 - accuracy: 0.3655\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 3.1001 - accuracy: 0.3692\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0817 - accuracy: 0.3725\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0622 - accuracy: 0.3745\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 3.0398 - accuracy: 0.3792\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0228 - accuracy: 0.3813\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0044 - accuracy: 0.3844\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9811 - accuracy: 0.3893\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9612 - accuracy: 0.3925\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9484 - accuracy: 0.3927\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9282 - accuracy: 0.3961\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.9197 - accuracy: 0.3970\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8979 - accuracy: 0.4020\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.8831 - accuracy: 0.4050\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8684 - accuracy: 0.4068\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8445 - accuracy: 0.4109\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8299 - accuracy: 0.4136\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8182 - accuracy: 0.4163\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8024 - accuracy: 0.4185\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7846 - accuracy: 0.4213\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7736 - accuracy: 0.4242\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7594 - accuracy: 0.4258\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7466 - accuracy: 0.4282\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7319 - accuracy: 0.4292\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7232 - accuracy: 0.4305\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7033 - accuracy: 0.4346\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6900 - accuracy: 0.4371\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6841 - accuracy: 0.4380\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6704 - accuracy: 0.4403\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6567 - accuracy: 0.4418\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6451 - accuracy: 0.4453\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6388 - accuracy: 0.4439\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6245 - accuracy: 0.4484\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6208 - accuracy: 0.4487\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6033 - accuracy: 0.4508\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6071 - accuracy: 0.4500\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5805 - accuracy: 0.4570\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5692 - accuracy: 0.4576\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5596 - accuracy: 0.4589\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5462 - accuracy: 0.4611\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5393 - accuracy: 0.4640\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5263 - accuracy: 0.4654\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5266 - accuracy: 0.4654\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5198 - accuracy: 0.4667\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5045 - accuracy: 0.4683\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4973 - accuracy: 0.4691\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4833 - accuracy: 0.4719\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4736 - accuracy: 0.4743\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4680 - accuracy: 0.4747\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4530 - accuracy: 0.4769\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4489 - accuracy: 0.4769\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4465 - accuracy: 0.4772\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4361 - accuracy: 0.4790\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4270 - accuracy: 0.4808\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4254 - accuracy: 0.4830\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.4119 - accuracy: 0.4849\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4049 - accuracy: 0.4850\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4021 - accuracy: 0.4873\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3857 - accuracy: 0.4891\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3758 - accuracy: 0.4914\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3735 - accuracy: 0.4909\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3712 - accuracy: 0.4909\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rOqmmarvlSLh",
        "outputId": "2823a49a-b234-4755-fce6-30c29f1b7eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate better lyrics!\n",
        "\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P96oVMk3lU7y",
        "outputId": "e5074162-42d6-4d1a-a581-21709cc53ec7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 665ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "im feeling chills me to the glass filled with the age man money love loud mental buddy ho hungry helen am mistake books call birds longer cutie cutie cutie beg beg beg answer first outward moon police corner thing thing melody mistake dancing streets its so new your friends friend back back row laughing going valley valley nights gimme gimme sorry begun visitors visitors stars or one sacrificed tale papers one thing way thing row to notion book but more round and melody paper rights desire a feeling no more of the moon yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lZe9gaJeoGVP",
        "outputId": "26b3663f-7107-432f-9e24-26ae3f132f3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ee7WKgRGrJy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a7632b-ba00-4d51-ec94-658bf6824f31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "im feeling chills in is another people leaves if it wasnt there is the time knows you to speaking but girl but to say ahha but no way that you women messin worlds mama different track love loud mental buddy fuse buddy buddy clothes judge never lookin choice but messin messin anything somehow loneliness reflections oasis appetite darkness trust smoking darkness check thing i dark and dying ba painted darkness dogs act lives messin write evening light we letters back and little of carry your bloody sword street dull farm called jeanie but price to bluest am you office if i really always\n"
          ]
        }
      ],
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hYvvj-65ndVw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "l10c04_nlp_optimizing_the_text_generation_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}